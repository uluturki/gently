{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualization is based on a plotly example that can be found here: https://plot.ly/python/3d-network-graph/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# maybe put all this in __init__.py ?\n",
    "import gently as mz\n",
    "import gently.physics \n",
    "import gently.simulation \n",
    "import gently.geometry \n",
    "import gently.visualization \n",
    "import gently.metrics \n",
    "import gently.terrain\n",
    "\n",
    "import networkx as nx\n",
    "#Plotly seems very nice but I think it's not very open dand kinda commercial so keep an eye on that!\n",
    "import plotly as py\n",
    "import plotly.graph_objs as go\n",
    "import math\n",
    "import copy\n",
    "import random\n",
    "%matplotlib inline \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "#import scipy.stats as ss\n",
    "import pyswarms as ps\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Global Parameters (here so can be played around easily)\n",
    "# Random seed is fixed for reproducibility\n",
    "random.seed(42) # This doesn't fix for scipy.stats so moved everything to random. \n",
    "# scipy.stats wasn't really helping with anything anyway, removed one dependency this way...\n",
    "\n",
    "\n",
    "# Population Paratemeters\n",
    "N = 400\n",
    "N_building_frac = 150/400; # This is the number of nodes that are reserved solely for buildings.\n",
    "                                # Buildings may (likely) end up with more nodes due to reg. nodes falling in buildings\n",
    "N_building_reserved = int(N*N_building_frac)\n",
    "N_node = N-N_building_reserved # excluding building ones, they are generated seperately.\n",
    "N_b = 9 # let's try 6 APs, so optimization is a bit easier...\n",
    "\n",
    "# Sim Parameters\n",
    "d_basestation = 0.125 # AP comm range, normalized\n",
    "d_node = 0.001   # node comm range, normalized\n",
    "pcost_node = 1  # Cost of node-node transmission\n",
    "pcost_basestation = 1.5  # cost of node-AP transmission\n",
    "dim = 5; #3D\n",
    "\n",
    "# Optimization Parameters\n",
    "n_swarm = 200\n",
    "n_iter = 75\n",
    "\n",
    "# about saving and stuff\n",
    "file_name = '2D_Nb' + str(N_b) + '_db' + str(d_basestation) + '_dn' + str(d_node) + '_' + str(n_swarm) + '_' + str(n_iter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Generate buildings first so buildings can be filled accordingly.\n",
    "\n",
    "# @TODO: Automatize this by having a grid and deciding if to place a building at each grid point via a probability \n",
    "# and randomizing the sizes. Fully random can be done by doing 2D rectangle-rectange collusion checks, however\n",
    "# grid is more realistic for US Urban scenario than a random mess. Thats more of a continental thing :)\n",
    "\n",
    "base_origin = mz.geometry.Point(0.2, 0.3, 0)\n",
    "base_size = {'length':0.1, 'width':0.15}\n",
    "height = 0.2\n",
    "\n",
    "#                    {'base':{'x': 0.45, 'y':0.6, 'z':0},'size':{'length':0.2, 'width':0.1},'height':0.05},\n",
    "pert_param_list = [ {'base':mz.geometry.Point(0.2,0.55,0)  ,'size':{'length':0.1, 'width':0.15}    ,'height': 0.085},\n",
    "                    {'base':mz.geometry.Point(0.6,0.35,0)  ,'size':{'length':0.1, 'width':0.1}     ,'height':0.125},\n",
    "                    {'base':mz.geometry.Point(0.3,0.2,0)   ,'size':{'length':0.15, 'width':0.2}    ,'height':0.065},\n",
    "                    {'base':mz.geometry.Point(0.7,0.8,0)   ,'size':{'length':0.075, 'width':0.1}   ,'height':0.1},\n",
    "                    {'base':mz.geometry.Point(0.15,0.35,0) ,'size':{'length':0.075, 'width':0.1}   ,'height':0.06},\n",
    "                    {'base':mz.geometry.Point(0.45,0.65,0) ,'size':{'length':0.125, 'width':0.1}   ,'height':0.060},\n",
    "                    {'base':mz.geometry.Point(0.45,0.45,0) ,'size':{'length':0.085, 'width':0.095} ,'height':0.075}\n",
    "                  ]\n",
    "\n",
    "pert_list = [mz.geometry.RectPrism(p['base'],p['size'],p['height']) for p in pert_param_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## First generate the population\n",
    "\n",
    "# Populate Nodes\n",
    "# Generate the x-y coordinates (@TODO we also need to make sure there are no duplicate 3D coordinates)\n",
    "mu = 0;\n",
    "rho = 5;\n",
    "#x = ss.norm.rvs(loc=mu,scale=rho,size=N)\n",
    "\n",
    "#x = np.array([random.gauss(mu,rho) for n in np.arange(N_node)])\n",
    "#x = [s + abs(min(x)) for s in x]\n",
    "# Trying with uniform dist.\n",
    "x = np.array([random.uniform(0, 1) for n in np.arange(N_node)])\n",
    "\n",
    "\n",
    "#y = ss.norm.rvs(loc=mu,scale=rho,size=N)\n",
    "#y = np.array([random.gauss(mu,rho) for n in np.arange(N_node)])\n",
    "#y = [s + abs(min(y)) for s in y]\n",
    "# Trying with uniform dist.\n",
    "y = np.array([random.uniform(0, 1) for n in np.arange(N_node)])\n",
    "\n",
    "\n",
    "# generate nodes that will be inside the buildings. Can put them on base points of buildings, they will get \n",
    "# mixed into the building when conform function is called.\n",
    "x_building = np.array([])\n",
    "y_building = np.array([])\n",
    "h_building = np.array([])\n",
    "    \n",
    "#sf = max(max(x),max(y))\n",
    "#x = x/sf;\n",
    "#y = y/sf;\n",
    "\n",
    "# to make it work with uniform\n",
    "sf = 25\n",
    "\n",
    "# These are already normalized, so don't do it twice.\n",
    "for idx in np.arange(N_building_reserved):\n",
    "    pert = random.choice(pert_list)\n",
    "    x_building = np.append(x_building,pert.base_origin.x)\n",
    "    y_building = np.append(y_building,pert.base_origin.y)\n",
    "    h_building = np.append(h_building,pert.base_origin.z)\n",
    "# append new building nodes into the lists\n",
    "x = np.append(x,x_building)\n",
    "y = np.append(y,y_building)\n",
    "\n",
    "\n",
    "# Generate z axis(height), heavily around zero.\n",
    "lambd = 10\n",
    "low = 0\n",
    "high = 0.1\n",
    "\n",
    "#h = ss.expon.rvs(loc=0,scale=1/lambd,size=N)\n",
    "h = np.array([random.expovariate(lambd) for n in np.arange(N_node)])\n",
    "h = h/(sf*2)*2 # @TODO: Hack Solution! Fix sampling of height!!\n",
    "# append new building nodes into the lists, here because they are already normalized\n",
    "h = np.append(h,h_building)\n",
    "# Normalize the coordinates to be in a unit cube\n",
    "node_coordinates = (x,y,h)\n",
    "\n",
    "# Populate basestations\n",
    "\n",
    "bs_range = (0.1,0.9) # Outlying box of AP rectangle\n",
    "h_bs = 0.005; # starting height for APs\n",
    "\n",
    "x_list = np.linspace(bs_range[0],bs_range[1],int(math.sqrt(N_b)))\n",
    "y_list = np.linspace(bs_range[0],bs_range[1],int(math.sqrt(N_b)))\n",
    "xx, yy = np.meshgrid(x_list, y_list)\n",
    "\n",
    "x_basestation = [] \n",
    "y_basestation = []\n",
    "for i in range(len(xx)):\n",
    "    for j in range(len(yy)):\n",
    "        x_basestation.append(xx[i,j]) \n",
    "        y_basestation.append(yy[i,j])\n",
    "\n",
    "x_basestation = np.array(x_basestation)\n",
    "y_basestation = np.array(y_basestation)\n",
    "\n",
    "#sf = max(max(x_basestation),max(y_basestation))\n",
    "#x_basestation = x_basestation/sf\n",
    "#y_basestation = y_basestation/sf\n",
    "\n",
    "#h_basestation = np.ones(N_b) * np.mean(node_coordinates[2])\n",
    "h_basestation = np.ones(N_b)*h_bs\n",
    "\n",
    "basestation_coordinates = (x_basestation,y_basestation,h_basestation) # couldn't do this in a better way for some reason.\n",
    "\n",
    "# Convert into dictionary and give every vertex their unique id\n",
    "node_keys = np.arange(N)\n",
    "node_coordinates_dict = {i: (node_coordinates[0][i],\n",
    "                             node_coordinates[1][i],\n",
    "                             node_coordinates[2][i]) for i in node_keys}\n",
    "# Dictionary keys will also be node id's so have to make them unique\n",
    "basestation_keys = np.arange(N,N+N_b)\n",
    "basestation_coordinates_dict = {i: (basestation_coordinates[0][i-N],\n",
    "                                    basestation_coordinates[1][i-N],\n",
    "                                    basestation_coordinates[2][i-N]) for i in basestation_keys}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Construct the network and prepare the stage\n",
    "\n",
    "coordinates = {'node': node_coordinates_dict, 'basestation': basestation_coordinates_dict}\n",
    "radii = {'node': d_node, 'basestation': d_basestation}\n",
    "costs = {'node': pcost_node, 'basestation': pcost_basestation}\n",
    "\n",
    "S = mz.simulation.SimStage(coordinates,radii,costs)\n",
    "\n",
    "G = S.G_dict['combined']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Decide on the terrain and update the stage accordingly.\n",
    "\n",
    "t_params = {'range': {'low':0.3,'high':0.75},'height':0.1}\n",
    "S.update_terrain(mz.terrain.surface_height_func4,t_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 532 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "## Update the stage with buildings \n",
    "S.update_perturbations(pert_list) #0ns\n",
    "S.conform_node_heights(['node','basestation']) #41ms\n",
    "S.update_connections()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Visualize to see what everything looks like\n",
    "# Enter the params for the network to be visualized\n",
    "mz.visualization.visualize_stage(S,figure_name='module_test_' +file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "network is NOT connected\n",
      "percentage connected:0.2675\n",
      "k-connectedness k:1\n",
      "average shortest path length:1.9261083743842364\n",
      "average shortest path length(weighted):2.8866995073891624\n"
     ]
    }
   ],
   "source": [
    "## Compute Initial performance metrics\n",
    "G_met = S.G_dict['combined']\n",
    "\n",
    "is_conn = mz.metrics.is_connected(G_met)\n",
    "if is_conn == True:\n",
    "    print('network IS connected')\n",
    "else: \n",
    "    print('network is NOT connected')\n",
    "\n",
    "bs_keys = S.coordinates_dict_base['basestation'].keys()\n",
    "conn_frac = mz.metrics.connected_fraction(G_met,True,bs_keys)\n",
    "print('percentage connected:' + str(conn_frac))\n",
    "\n",
    "conn_k = mz.metrics.k_connectedness(G_met)\n",
    "print('k-connectedness k:' + str(conn_k[1]))\n",
    "\n",
    "avg_path = mz.metrics.avg_shortest_path_length(G_met)\n",
    "print('average shortest path length:' + str(avg_path[1]))\n",
    "\n",
    "avg_path_weighted = mz.metrics.avg_shortest_path_length(G_met,'power_cost')\n",
    "print('average shortest path length(weighted):' + str(avg_path_weighted[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Grid search is not doable, going with Particle Swarm\n",
    "def network_sim_2d(params):\n",
    "    \"\"\"Network Simulation as objective function\n",
    "\n",
    "    This computes a network simulation for given AP locations\n",
    "    and returns the goal, which is the connected percentage\n",
    "\n",
    "    Inputs\n",
    "    ------\n",
    "    params: np.ndarray\n",
    "        Unrolled version of the coordinates for each access point\n",
    "        ((x1,y1),(x2,y2),...,h) last one is the height for all, since\n",
    "        this is 2D\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        The computed unconnected percentage of the network \n",
    "        (unconnected because expects cost to return)\n",
    "    \"\"\"\n",
    "    # Unroll the received parameters into coordinates\n",
    "    \n",
    "    h = params[-1] # height is the last element\n",
    "    #print(params)\n",
    "    #print(h)\n",
    "    n_axes = 2 # only (x,y)\n",
    "    n_aps = int((len(params)-1)/n_axes)\n",
    "    # excluding last element from reshape\n",
    "    xy_array = params[:-1].reshape((n_aps,n_axes)) \n",
    "    #print(xy_array)\n",
    "    x_array = xy_array[:,0]\n",
    "    y_array = xy_array[:,1]\n",
    "    #print(x_array)\n",
    "    #print(y_array)\n",
    "    h_array = np.empty(n_aps);\n",
    "    h_array.fill(h) # create a list of same height (2D approx.) for all APs\n",
    "    \n",
    "    # Perform the network simulation\n",
    "    \n",
    "    # Here should check if all basestation coordinates are viable, and continue to next coordinate if not.\n",
    "    # this will seriously mess with the optimizer though, I don't know what to do about that. Maybe use discrete\n",
    "    # values.\n",
    "\n",
    "    S.update_node_coordinates(x_array,y_array,h_array,n_type='basestation')\n",
    "    S.update_connections()\n",
    "    G_met = S.G_dict['combined']\n",
    "    # avg length of shortest paths, LINK WEIGHTED \n",
    "    # First check if the network is connected \n",
    "    \n",
    "    # find the basestations that are ABOVE ground.\n",
    "    viable_bs_list = list()\n",
    "    for bs_key in S.coordinates_dict['basestation'].keys():\n",
    "        c_p = S.coordinates_dict['basestation'][bs_key] #height\n",
    "        c_h = c_p[2]\n",
    "        t_h = S.terrain_function(mz.geometry.Point(c_p[0],c_p[1],0), S.terrain_params)\n",
    "        \n",
    "        if t_h <= c_h:\n",
    "            viable_bs_list.append(bs_key)\n",
    "            \n",
    "    # Compute the cost\n",
    "    conn_frac = mz.metrics.connected_fraction(G_met,True,viable_bs_list) \n",
    "    # conn_frac is gain, need to return loss\n",
    "    loss = 1 - conn_frac # fraction of unconnected nodes\n",
    "    #print(loss)\n",
    "    return loss\n",
    "\n",
    "def f_2d(x):\n",
    "    \"\"\"Higher-level method to do the simulation for the\n",
    "    whole swarm.\n",
    "\n",
    "    Inputs\n",
    "    ------\n",
    "    x: numpy.ndarray of shape (n_particles, dimensions)\n",
    "        The swarm that will perform the search\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    numpy.ndarray of shape (n_particles, )\n",
    "        The computed loss for each particle\n",
    "    \"\"\"\n",
    "    #print('selams')\n",
    "    n_particles = x.shape[0] # this can be parallelized...\n",
    "    j = [network_sim_2d(x[i]) for i in range(n_particles)]\n",
    "    #print(x[0])\n",
    "    #print(x[1])\n",
    "    #print(str(j[0]) + ' ' + str(j[1]) + ' ' + str(j[2]) + ' ' + str(j[3]))\n",
    "    return np.array(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pyswarms.single.local_best:Iteration 1/75, cost: 0.6699999999999999\n",
      "INFO:pyswarms.single.local_best:Iteration 2/75, cost: 0.6699999999999999\n",
      "INFO:pyswarms.single.local_best:Iteration 3/75, cost: 0.6699999999999999\n",
      "INFO:pyswarms.single.local_best:Iteration 4/75, cost: 0.6475\n",
      "INFO:pyswarms.single.local_best:Iteration 5/75, cost: 0.64\n",
      "INFO:pyswarms.single.local_best:Iteration 6/75, cost: 0.64\n",
      "INFO:pyswarms.single.local_best:Iteration 7/75, cost: 0.64\n",
      "INFO:pyswarms.single.local_best:Iteration 8/75, cost: 0.635\n",
      "INFO:pyswarms.single.local_best:Iteration 9/75, cost: 0.63\n",
      "INFO:pyswarms.single.local_best:Iteration 10/75, cost: 0.6125\n",
      "INFO:pyswarms.single.local_best:Iteration 11/75, cost: 0.6125\n",
      "INFO:pyswarms.single.local_best:Iteration 12/75, cost: 0.585\n",
      "INFO:pyswarms.single.local_best:Iteration 13/75, cost: 0.5800000000000001\n",
      "INFO:pyswarms.single.local_best:Iteration 14/75, cost: 0.5725\n",
      "INFO:pyswarms.single.local_best:Iteration 15/75, cost: 0.5625\n",
      "INFO:pyswarms.single.local_best:Iteration 16/75, cost: 0.5625\n",
      "INFO:pyswarms.single.local_best:Iteration 17/75, cost: 0.5625\n",
      "INFO:pyswarms.single.local_best:Iteration 18/75, cost: 0.5625\n",
      "INFO:pyswarms.single.local_best:Iteration 19/75, cost: 0.56\n",
      "INFO:pyswarms.single.local_best:Iteration 20/75, cost: 0.5575\n",
      "INFO:pyswarms.single.local_best:Iteration 21/75, cost: 0.5575\n",
      "INFO:pyswarms.single.local_best:Iteration 22/75, cost: 0.5575\n",
      "INFO:pyswarms.single.local_best:Iteration 23/75, cost: 0.5575\n",
      "INFO:pyswarms.single.local_best:Iteration 24/75, cost: 0.5575\n",
      "INFO:pyswarms.single.local_best:Iteration 25/75, cost: 0.5575\n",
      "INFO:pyswarms.single.local_best:Iteration 26/75, cost: 0.5575\n",
      "INFO:pyswarms.single.local_best:Iteration 27/75, cost: 0.5575\n",
      "INFO:pyswarms.single.local_best:Iteration 28/75, cost: 0.5575\n",
      "INFO:pyswarms.single.local_best:Iteration 29/75, cost: 0.5575\n",
      "INFO:pyswarms.single.local_best:Iteration 30/75, cost: 0.5575\n",
      "INFO:pyswarms.single.local_best:Iteration 31/75, cost: 0.5575\n",
      "INFO:pyswarms.single.local_best:Iteration 32/75, cost: 0.5575\n",
      "INFO:pyswarms.single.local_best:Iteration 33/75, cost: 0.5575\n",
      "INFO:pyswarms.single.local_best:Iteration 34/75, cost: 0.5575\n",
      "INFO:pyswarms.single.local_best:Iteration 35/75, cost: 0.5575\n",
      "INFO:pyswarms.single.local_best:Iteration 36/75, cost: 0.5575\n",
      "INFO:pyswarms.single.local_best:Iteration 37/75, cost: 0.5575\n",
      "INFO:pyswarms.single.local_best:Iteration 38/75, cost: 0.5575\n",
      "INFO:pyswarms.single.local_best:Iteration 39/75, cost: 0.5575\n",
      "INFO:pyswarms.single.local_best:Iteration 40/75, cost: 0.5575\n",
      "INFO:pyswarms.single.local_best:Iteration 41/75, cost: 0.5575\n",
      "INFO:pyswarms.single.local_best:Iteration 42/75, cost: 0.5575\n",
      "INFO:pyswarms.single.local_best:Iteration 43/75, cost: 0.5575\n",
      "INFO:pyswarms.single.local_best:Iteration 44/75, cost: 0.5575\n",
      "INFO:pyswarms.single.local_best:Iteration 45/75, cost: 0.5575\n",
      "INFO:pyswarms.single.local_best:Iteration 46/75, cost: 0.5575\n",
      "INFO:pyswarms.single.local_best:Iteration 47/75, cost: 0.5575\n",
      "INFO:pyswarms.single.local_best:Iteration 48/75, cost: 0.5575\n",
      "INFO:pyswarms.single.local_best:Iteration 49/75, cost: 0.5575\n",
      "INFO:pyswarms.single.local_best:Iteration 50/75, cost: 0.5575\n",
      "INFO:pyswarms.single.local_best:Iteration 51/75, cost: 0.5549999999999999\n",
      "INFO:pyswarms.single.local_best:Iteration 52/75, cost: 0.55\n",
      "INFO:pyswarms.single.local_best:Iteration 53/75, cost: 0.55\n",
      "INFO:pyswarms.single.local_best:Iteration 54/75, cost: 0.55\n",
      "INFO:pyswarms.single.local_best:Iteration 55/75, cost: 0.55\n",
      "INFO:pyswarms.single.local_best:Iteration 56/75, cost: 0.55\n",
      "INFO:pyswarms.single.local_best:Iteration 57/75, cost: 0.55\n",
      "INFO:pyswarms.single.local_best:Iteration 58/75, cost: 0.55\n",
      "INFO:pyswarms.single.local_best:Iteration 59/75, cost: 0.55\n",
      "INFO:pyswarms.single.local_best:Iteration 60/75, cost: 0.55\n",
      "INFO:pyswarms.single.local_best:Iteration 61/75, cost: 0.55\n",
      "INFO:pyswarms.single.local_best:Iteration 62/75, cost: 0.55\n",
      "INFO:pyswarms.single.local_best:Iteration 63/75, cost: 0.55\n",
      "INFO:pyswarms.single.local_best:Iteration 64/75, cost: 0.55\n",
      "INFO:pyswarms.single.local_best:Iteration 65/75, cost: 0.5475\n",
      "INFO:pyswarms.single.local_best:Iteration 66/75, cost: 0.5475\n",
      "INFO:pyswarms.single.local_best:Iteration 67/75, cost: 0.5475\n",
      "INFO:pyswarms.single.local_best:Iteration 68/75, cost: 0.5475\n",
      "INFO:pyswarms.single.local_best:Iteration 69/75, cost: 0.5475\n",
      "INFO:pyswarms.single.local_best:Iteration 70/75, cost: 0.5475\n",
      "INFO:pyswarms.single.local_best:Iteration 71/75, cost: 0.5475\n",
      "INFO:pyswarms.single.local_best:Iteration 72/75, cost: 0.5475\n",
      "INFO:pyswarms.single.local_best:Iteration 73/75, cost: 0.5475\n",
      "INFO:pyswarms.single.local_best:Iteration 74/75, cost: 0.5475\n",
      "INFO:pyswarms.single.local_best:Iteration 75/75, cost: 0.5475\n",
      "INFO:pyswarms.single.local_best:================================\n",
      "Optimization finished!\n",
      "Final cost: 0.5475\n",
      "Best value: [ 0.252843 0.764403 0.898377 ...]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4h 20min 2s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# bounds, not my best but I'm really sleepy...\n",
    "max_bound = 1 * np.ones(N_b*2)#xy bounds\n",
    "min_bound = np.zeros(N_b*2)   #xy bounds\n",
    "max_bound = np.append(max_bound,0.125) #h bound\n",
    "min_bound = np.append(min_bound,0.025)  #h bound\n",
    "\n",
    "bounds = (min_bound, max_bound)\n",
    "\n",
    "\n",
    "# Initialize swarm, arbitrary for now. This can also be searched for apparently...\n",
    "#options = {'c1': 0.5, 'c2': 0.3, 'w':0.3} #optimizing this didn't work very well for some reason, check that again.\n",
    "options = {'c1': 0.5, 'c2': 0.3, 'w': 0.4, 'k': 20, 'p': 2}\n",
    "# Call instance of PSO, also remember constraints\n",
    "dimensions = ((2 * N_b) + 1)\n",
    "optimizer = ps.single.LocalBestPSO(n_particles=n_swarm, dimensions=dimensions, options=options, bounds=bounds)\n",
    "\n",
    "# Perform optimization # each iteration appears to be the same, warum?\n",
    "cost, pos = optimizer.optimize(f_2d, print_step=1, iters=n_iter, verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# Obtain the cost history\n",
    "cost_history_2d = optimizer.get_cost_history\n",
    "# Obtain the position history\n",
    "pos_history_2d = optimizer.get_pos_history\n",
    "# Obtain the velocity history\n",
    "velocity_history = optimizer.get_velocity_history\n",
    "\n",
    "pickle.dump((cost_history_2d,pos_history_2d,velocity_history),open('opt_results_'+ file_name +'.p','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "h = pos[-1] # height is the last element\n",
    "#print(params)\n",
    "#print(h)\n",
    "n_axes = 2 # only (x,y)\n",
    "n_aps = int((len(pos)-1)/n_axes)\n",
    "# excluding last element from reshape\n",
    "xy_array = pos[:-1].reshape((n_aps,n_axes)) \n",
    "#print(xy_array)\n",
    "x_array = xy_array[:,0]\n",
    "y_array = xy_array[:,1]\n",
    "#print(x_array)\n",
    "#print(y_array)\n",
    "h_array = np.empty(n_aps);\n",
    "h_array.fill(h) # create a list of same height (2D approx.) for all APs\n",
    "\n",
    "S.update_node_coordinates(x_array,y_array,h_array,n_type='basestation')\n",
    "S.update_connections()\n",
    "G_met = S.G_dict['combined']\n",
    "# avg length of shortest paths, LINK WEIGHTED \n",
    "# First check if the network is connected \n",
    "\n",
    "# Compute the cost\n",
    "conn_frac = mz.metrics.connected_fraction(G_met,True,S.coordinates_dict_base['basestation'].keys()) \n",
    "\n",
    "mz.visualization.visualize_stage(S,figure_name='opt_result_' +file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
